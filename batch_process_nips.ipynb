{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b7e146-e304-408f-839c-0bbb26ba6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from utils import nips_parser\n",
    "import pickle\n",
    "import google.generativeai as genai\n",
    "import utils.paper_ontology as po\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Markdown\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=\"<>\")\n",
    "flash = genai.GenerativeModel('gemini-1.5-flash')\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"<>\"\n",
    "\n",
    "PROJECT_DIR = './examples/nips_2024'\n",
    "\n",
    "project_dir = Path(PROJECT_DIR)\n",
    "project_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "paper_pdf_dir = Path(PROJECT_DIR, 'paper_pdfs')\n",
    "paper_pdf_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "paper_parsed_dir = Path(PROJECT_DIR, 'paper_parsed.pkl')\n",
    "\n",
    "paper_summaries = Path(PROJECT_DIR, 'paper_summaries')\n",
    "paper_summaries.mkdir(exist_ok=True, parents=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01f089-3468-4970-9f90-a55ed32af4be",
   "metadata": {},
   "source": [
    "## Download and Parse all NIPS papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ddf64a-a9d3-4f25-bfd7-656917680e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████                                                                | 810/4499 [37:36<298:37:51, 291.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve <a href=\"/paper_files/paper/2024/hash/2d66a70c770de7835678f1c1e65fe5e1-Abstract-Conference.html\" title=\"paper title\">GoMatching: A Simple Baseline for Video Text Spotting via Long and Short Term Matching</a>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████▌                                                 | 1532/4499 [1:59:38<681:22:08, 826.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve <a href=\"/paper_files/paper/2024/hash/5681251fa039cf49d6d11b906eded1b3-Abstract-Conference.html\" title=\"paper title\">Identification and Estimation of the Bi-Directional MR with Some Invalid Instruments</a>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████▋                                        | 2083/4499 [2:49:11<423:17:19, 630.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve <a href=\"/paper_files/paper/2024/hash/77dd8e90fe833eba5fae86cf017d7a56-Abstract-Conference.html\" title=\"paper title\">AsCAN: Asymmetric Convolution-Attention Networks for Efficient Recognition and Generation</a>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████████████████████████████▍                                 | 2485/4499 [3:30:52<220:48:42, 394.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve <a href=\"/paper_files/paper/2024/hash/8ea50bf458f6070548b11babbe0bf89b-Abstract-Conference.html\" title=\"paper title\">Dual-Diffusion for Binocular 3D Human Pose Estimation</a>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████▉                           | 2919/4499 [3:45:21<24:55:55, 56.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve <a href=\"/paper_files/paper/2024/hash/a730abbcd6cf4a371ca9545db5922442-Abstract-Conference.html\" title=\"paper title\">Improved Analysis for Bandit Learning in Matching Markets</a>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████             | 3711/4499 [5:21:52<298:48:31, 1365.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve <a href=\"/paper_files/paper/2024/hash/d3d1947ba438c758790b18d5fcf69e8f-Abstract-Conference.html\" title=\"paper title\">An In-depth Investigation of Sparse Rate Reduction in Transformer-like Models</a>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████▌     | 4174/4499 [5:44:50<12:30:10, 138.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve <a href=\"/paper_files/paper/2024/hash/ed24eafde44aef581b9f605319583b6d-Abstract-Conference.html\" title=\"paper title\">Wormhole Loss for Partial Shape Matching</a>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 4499/4499 [5:53:40<00:00,  4.72s/it]\n"
     ]
    }
   ],
   "source": [
    "#from utils.download_pdfs_from_url import download_nips\n",
    "\n",
    "#_ = download_nips('https://papers.nips.cc/paper_files/paper/2024', paper_pdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52eaef80-b6ef-4628-ab77-6a8abcdef0f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▉                                                                                | 144/4028 [01:14<30:41,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n",
      "MuPDF error: syntax error: unknown keyword: 'literal'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▏                                                                     | 643/4028 [07:09<30:34,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'gs0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'gs0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'gs0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'gs0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'gs0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'gs0'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'gs0'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████▊                                                                     | 669/4028 [07:29<24:29,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (327 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (422 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (573 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (602 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (1059 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▎                                                                | 891/4028 [10:02<24:35,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████▌                                                          | 1156/4028 [13:43<44:38,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████████████▍                                                    | 1443/4028 [17:30<17:37,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▍                                                  | 1542/4028 [19:00<40:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████▌                                               | 1700/4028 [20:55<16:45,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: could not parse color space (497 0 R)\n",
      "\n",
      "MuPDF error: syntax error: could not parse color space (710 0 R)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|█████████████████████████████████████████████████████▏                            | 2610/4028 [31:36<09:19,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|███████████████████████████████████████████████████████▏                          | 2710/4028 [32:47<33:53,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: syntax error: cannot find ExtGState resource 'GS8'\n",
      "\n",
      "MuPDF error: syntax error: cannot find ExtGState resource 'GS8'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████▍                         | 2773/4028 [33:23<07:56,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████████████████▍             | 3360/4028 [40:52<04:58,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n",
      "MuPDF error: unsupported error: cannot create appearance stream for Screen annotations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 4028/4028 [48:48<00:00,  1.38it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m all_papers \u001b[38;5;241m=\u001b[39m nips_parser\u001b[38;5;241m.\u001b[39mparse_folder(paper_pdf_dir)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(paper_parsed_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(all_papers, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "#all_papers = nips_parser.parse_folder(paper_pdf_dir)\n",
    "#with open(paper_parsed_dir, 'wb') as f:\n",
    "#    pickle.dump(all_papers, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c1936-c8dc-4117-a171-0796ba9f4683",
   "metadata": {},
   "source": [
    "## Load papers from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6574b828-da7b-4add-80ce-6d8ac0e5afb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4028"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(paper_parsed_dir, 'rb') as f:\n",
    "    all_papers = pickle.load(f)\n",
    "\n",
    "len(all_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71243337-54ed-4d3a-aa29-9082fae3fc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'authors', 'sections'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_papers[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff4f003-c884-4c16-b143-ccf90b8c94e1",
   "metadata": {},
   "source": [
    "## Generate Paper Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6084b7a2-50ff-42cd-ab6d-d29ed37bd037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|▌                                                                     | 23/2758 [03:26<6:45:52,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|█▍                                                                    | 56/2758 [08:38<7:05:07,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|██▍                                                                   | 95/2758 [14:37<7:00:23,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|██▊                                                                  | 110/2758 [17:00<7:12:07,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n",
      "deadline\n",
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|███▍                                                               | 141/2758 [1:05:57<6:58:54,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|███▎                                                            | 143/2758 [2:13:02<617:50:42, 850.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n",
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|███▊                                                              | 159/2758 [2:48:19<11:17:50, 15.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|███▋                                                            | 161/2758 [3:56:20<624:21:18, 865.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  10%|███████                                                            | 289/2758 [5:13:45<6:01:58,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|███████                                                           | 294/2758 [5:29:36<50:34:27, 73.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|███████▌                                                           | 309/2758 [5:47:37<7:18:51, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|███████▋                                                           | 314/2758 [5:48:18<5:53:13,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  13%|████████▍                                                          | 346/2758 [6:08:05<5:32:45,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  13%|████████▊                                                          | 365/2758 [6:26:07<6:03:02,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|█████████▎                                                         | 382/2758 [6:46:14<6:20:16,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|█████████▋                                                         | 397/2758 [7:04:08<7:10:59, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|█████████▎                                                      | 399/2758 [7:27:35<197:32:00, 301.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  15%|█████████▍                                                       | 402/2758 [7:28:00<71:10:56, 108.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  15%|██████████▏                                                        | 418/2758 [7:45:39<6:20:14,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  18%|████████████▍                                                      | 510/2758 [8:16:16<5:10:17,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  19%|████████████                                                     | 513/2758 [8:31:49<88:23:30, 141.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  19%|████████████▎                                                     | 515/2758 [8:32:06<46:00:27, 73.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  19%|████████████▍                                                     | 520/2758 [8:49:01<55:42:01, 89.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  20%|█████████████                                                     | 544/2758 [9:14:22<21:13:17, 34.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  20%|█████████████▋                                                     | 563/2758 [9:32:17<5:08:37,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  21%|██████████████                                                     | 579/2758 [9:51:06<5:47:23,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  22%|██████████████▎                                                   | 598/2758 [10:09:03<5:12:18,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  22%|██████████████▋                                                   | 614/2758 [10:31:38<5:44:53,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  23%|███████████████                                                   | 629/2758 [10:48:56<5:57:06, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  23%|██████████████▉                                                  | 636/2758 [11:05:10<23:58:06, 40.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  23%|██████████████▌                                                | 637/2758 [11:15:27<125:41:32, 213.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  24%|███████████████▋                                                  | 653/2758 [11:33:39<6:08:04, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  24%|███████████████▉                                                  | 668/2758 [11:52:32<5:54:29, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  25%|████████████████▎                                                 | 683/2758 [12:11:08<5:56:11, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  25%|████████████████▊                                                 | 702/2758 [12:30:19<4:28:59,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  26%|█████████████████▏                                                | 718/2758 [12:49:36<5:26:01,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  27%|█████████████████▌                                                | 735/2758 [13:07:17<5:26:16,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  27%|██████████████████                                                | 755/2758 [13:26:24<4:50:17,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  28%|██████████████████▍                                               | 771/2758 [13:44:24<5:17:07,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  29%|██████████████████▊                                               | 787/2758 [14:03:29<5:02:08,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  29%|██████████████████▋                                              | 792/2758 [14:20:15<42:25:43, 77.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  29%|███████████████████▎                                              | 807/2758 [14:37:39<5:24:10,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  30%|███████████████████▋                                              | 822/2758 [14:57:01<5:26:03, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  30%|███████████████████▌                                             | 829/2758 [15:13:52<22:37:19, 42.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  31%|████████████████████▏                                             | 845/2758 [15:32:26<5:05:57,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  31%|████████████████████▋                                             | 862/2758 [15:50:02<4:51:37,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  32%|████████████████████▉                                             | 877/2758 [16:07:24<5:25:36, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  32%|█████████████████████▎                                            | 893/2758 [16:24:47<5:01:05,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  33%|█████████████████████▋                                            | 908/2758 [16:43:00<5:29:09, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|██████████████████████▏                                           | 925/2758 [17:01:17<4:43:42,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|█████████████████████▉                                           | 930/2758 [17:17:29<38:21:40, 75.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n",
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|█████████████████████▋                                          | 935/2758 [17:43:23<65:08:14, 128.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|██████████████████████▏                                          | 942/2758 [18:00:35<26:20:51, 52.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|██████████████████████▎                                          | 947/2758 [18:16:35<41:14:51, 81.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  35%|███████████████████████                                           | 962/2758 [18:33:55<5:22:35, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  35%|██████████████████████▍                                         | 966/2758 [18:51:15<56:00:36, 112.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  40%|█████████████████████████▊                                       | 1097/2758 [19:09:34<3:36:49,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  40%|█████████████████████████▉                                       | 1101/2758 [19:10:09<3:56:45,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  40%|█████████████████████████▋                                      | 1106/2758 [19:26:02<34:02:31, 74.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  41%|██████████████████████████▍                                      | 1121/2758 [19:43:33<4:44:32, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|██████████████████████████▉                                      | 1145/2758 [20:03:08<3:44:20,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  43%|███████████████████████████▋                                     | 1175/2758 [20:22:47<3:56:21,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  43%|███████████████████████████▍                                    | 1182/2758 [20:40:02<18:51:15, 43.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  43%|███████████████████████████▉                                     | 1188/2758 [20:40:56<5:37:08, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  44%|████████████████████████████▎                                    | 1201/2758 [20:59:21<5:55:55, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  44%|███████████████████████████▌                                   | 1204/2758 [21:17:17<71:16:41, 165.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  44%|████████████████████████████▋                                    | 1218/2758 [21:35:29<5:50:41, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|█████████████████████████████                                    | 1231/2758 [21:52:59<5:32:51, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|████████████████████████████▏                                  | 1236/2758 [22:17:17<46:58:47, 111.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|█████████████████████████████▍                                   | 1249/2758 [22:35:01<5:30:06, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  46%|█████████████████████████████▊                                   | 1263/2758 [22:52:43<5:08:09, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  46%|████████████████████████████▉                                  | 1268/2758 [23:18:20<48:24:15, 116.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  46%|██████████████████████████████▏                                  | 1282/2758 [23:36:47<4:53:39, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  47%|██████████████████████████████▌                                  | 1296/2758 [23:54:09<4:45:01, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  47%|██████████████████████████████▏                                 | 1301/2758 [24:04:55<21:17:41, 52.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  48%|███████████████████████████████▍                                 | 1334/2758 [24:19:43<3:48:27,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  49%|███████████████████████████████▉                                 | 1355/2758 [24:22:53<3:34:28,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  53%|██████████████████████████████████▋                              | 1471/2758 [24:42:37<3:26:10,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  54%|██████████████████████████████████▎                             | 1476/2758 [24:59:01<27:21:13, 76.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  59%|██████████████████████████████████████▌                          | 1638/2758 [25:39:57<2:48:32,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  61%|███████████████████████████████████████▊                         | 1691/2758 [25:47:38<2:22:48,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  64%|█████████████████████████████████████████▊                       | 1776/2758 [26:00:03<2:24:07,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  65%|████████████████████████████████████████▋                      | 1780/2758 [26:17:58<31:29:50, 115.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  65%|████████████████████████████████████████▋                      | 1781/2758 [26:33:34<98:17:23, 362.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  65%|█████████████████████████████████████████▍                      | 1785/2758 [26:34:10<25:18:56, 93.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  65%|██████████████████████████████████████████▎                      | 1798/2758 [26:51:52<3:41:11, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  65%|██████████████████████████████████████████▍                      | 1800/2758 [26:52:10<2:59:56, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  66%|██████████████████████████████████████████▊                      | 1817/2758 [27:10:09<2:40:32, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  66%|██████████████████████████████████████████▎                     | 1822/2758 [27:27:48<21:24:35, 82.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  68%|████████████████████████████████████████████                     | 1868/2758 [27:50:18<2:14:48,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  70%|█████████████████████████████████████████████▍                   | 1927/2758 [27:58:53<2:03:27,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  72%|███████████████████████████████████████████████                  | 1997/2758 [28:09:07<1:53:15,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  74%|████████████████████████████████████████████████▏                | 2043/2758 [28:16:03<1:58:13,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 2061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  75%|████████████████████████████████████████████████▋                | 2068/2758 [28:19:44<1:39:43,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 2087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  79%|███████████████████████████████████████████████████▎             | 2177/2758 [28:35:38<1:21:36,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  79%|███████████████████████████████████████████████████▋             | 2192/2758 [28:54:48<1:43:24, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  81%|████████████████████████████████████████████████████▊            | 2240/2758 [29:11:39<1:11:06,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  87%|██████████████████████████████████████████████████████████▎        | 2402/2758 [29:45:24<48:10,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 2422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  87%|██████████████████████████████████████████████████████████▌        | 2411/2758 [29:46:48<53:08,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 2432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|███████████████████████████████████████████████████████████▌       | 2452/2758 [29:52:51<46:21,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|██████████████████████████████████████████████████████▎      | 2453/2758 [31:33:43<154:21:33, 1821.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n",
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|██████████████████████████████████████████████████████▎      | 2455/2758 [33:56:02<226:07:11, 2686.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n",
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  91%|█████████████████████████████████████████████████████████████▏     | 2519/2758 [34:35:16<34:26,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████████████████████████████████████████████████████████▍     | 2528/2758 [34:36:34<32:03,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|███████████████████████████████████████████████████████████▋     | 2533/2758 [34:52:35<4:40:49, 74.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|███████████████████████████████████████████████████████████▊     | 2540/2758 [35:09:26<2:52:10, 47.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|███████████████████████████████████████████████████████████▉     | 2545/2758 [35:25:53<4:54:31, 82.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  93%|██████████████████████████████████████████████████████████████▎    | 2563/2758 [35:44:23<30:09,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  94%|██████████████████████████████████████████████████████████████▋    | 2583/2758 [36:02:44<28:12,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  97%|████████████████████████████████████████████████████████████████▉  | 2674/2758 [36:30:48<11:28,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 2697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  97%|████████████████████████████████████████████████████████████████▉  | 2675/2758 [36:30:57<11:33,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 2699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  98%|█████████████████████████████████████████████████████████████████▋ | 2703/2758 [36:34:52<07:57,  8.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing paper: 2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|██████████████████████████████████████████████████████████████████▏| 2723/2758 [36:37:40<05:00,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|██████████████████████████████████████████████████████████████████▎| 2728/2758 [36:53:56<37:42, 75.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deadline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|█████████████████████████████████████████████████████████████████▍| 2732/2758 [37:10:05<52:14, 120.57s/it]"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(desc=\"Processing\", total=len(all_papers[1270:]))\n",
    "\n",
    "i = 0\n",
    "while i < len(all_papers[1270:]):\n",
    "    try:\n",
    "        p = all_papers[1270:][i]\n",
    "        if len(p['sections']) == 0:\n",
    "            print('Missing paper: '+str(i))\n",
    "            i += 1\n",
    "            continue\n",
    "        paperO = po.PaperOntology(p, flash)\n",
    "        s = paperO.create_summary()\n",
    "        info = paperO.extract_info()\n",
    "        #It is very slow to generate ontology. so I disabled after 300+ papers processing\n",
    "        #try:\n",
    "        #    o = paperO.create_ontology_json()\n",
    "        #except json.JSONDecodeError:\n",
    "        #    paperO.ontology = {}\n",
    "        #    o = {}\n",
    "        #try:\n",
    "        #    o_str = paperO.create_ontology_str()\n",
    "        #except:\n",
    "        #    o_str = ''\n",
    "        #    paperO.ontology_str = ''\n",
    "        p['summary'] = s\n",
    "        p['info'] = info\n",
    "        p['ontology'] = {}#o\n",
    "        p['ontology_str'] = ''#o_str\n",
    "        fn = Path(paper_summaries, 'ps_'+str(i+1270)+'.pkl')\n",
    "        with open(fn, 'wb') as f:\n",
    "            pickle.dump(p, f)\n",
    "        i += 1\n",
    "        pbar.update(1)\n",
    "    except:\n",
    "        print('deadline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37994135-ac80-48a8-92a9-be28ee583db3",
   "metadata": {},
   "source": [
    "## Generate Paper Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56edf3d4-ad55-47af-b5a0-9c791692f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will load the latest greatest data \n",
    "all_papers = []\n",
    "for item in paper_summaries.iterdir():\n",
    "    with open(item, 'rb') as f:\n",
    "        all_papers.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f462df7-46be-43da-a0e6-3d2ecdfcbe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info = [p['info'] for p in all_papers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19eaeaa3-ef53-410a-9c23-28d6ac25a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = flash.generate_content(\n",
    "    '''\n",
    "    Summarize a short list (around 100) of paper categories from list of paper information. \\\n",
    "    For example, text to speech, reinforcement learning, video generation etc. \\\n",
    "    Only output the category name without other content. list of paper information: \\\n",
    "    ''' + str(all_info)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a252722-dbf2-4655-bce7-6f2685a80f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0d62f73-5be4-4273-b1ad-df6ecfa51748",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = flash.generate_content(\n",
    "    '''\n",
    "    Summarize a list of paper categories into higher level categories, without duplications. \\\n",
    "    For example, text to speech, reinforcement learning, video generation etc. \\\n",
    "    Only output the category name without other content. list of categories: \\\n",
    "    ''' + str(r.text.split('\\n'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ed76db1-7b1e-4b7a-b678-2b360aaf1897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Generative Models',\n",
       " 'Reinforcement Learning',\n",
       " 'Federated Learning',\n",
       " 'Large Language Models',\n",
       " 'Neural Networks',\n",
       " 'Optimization',\n",
       " 'AI Safety and Governance',\n",
       " 'Computer Vision',\n",
       " 'Graph Neural Networks',\n",
       " 'Time Series Analysis',\n",
       " 'Data Management',\n",
       " 'Causal Inference',\n",
       " '3D Modeling',\n",
       " 'Simulation',\n",
       " 'Automated Systems',\n",
       " 'Explainable AI',\n",
       " 'Quantum Computing',\n",
       " 'Neuroscience']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55340f6c-3a22-4f13-bb48-a6a652199517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3990it [17:19,  3.84it/s]\n"
     ]
    }
   ],
   "source": [
    "paper_cat = r2.text\n",
    "\n",
    "for i,p in tqdm(enumerate(all_papers)):\n",
    "    r = flash.generate_content(\n",
    "        f'''\n",
    "        Assign the paper into one of the categories based on paper information in json format. \\\n",
    "        Only output the category name without other content. \\\n",
    "        Paper information: {str(p['info'])}. List of categories: {paper_cat}. \n",
    "        '''\n",
    "    )\n",
    "    all_papers[i]['info']['category'] = r.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4b0e2-8669-4306-974a-68863feb6bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88b4c629-058f-441a-b48a-919475dc0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(PROJECT_DIR, 'all_papers.pkl'), 'wb') as f:\n",
    "    pickle.dump(all_papers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7477eae2-dbe4-4f06-9f5f-cdf02a5b0a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3990"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997faaa-7a83-4437-ab24-188b89220072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d6ffbcc-134c-420c-b2b2-d976831d9c4f",
   "metadata": {},
   "source": [
    "## Generate Conference Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42178e5c-28bb-4647-ab2b-0f5a0fa39a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.paper_ontology import create_overview\n",
    "\n",
    "o_1 = create_overview([[p['summary'] for p in all_papers[:700]]], flash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62dc0313-4052-459f-9492-ec1b396a0a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello everyone!  Today, we're going on an exciting adventure into the world of computer science!  Imagine computers that can understand pictures and videos, write stories, and even help design new products – that's what computer scientists do.  I'm going to tell you about some amazing things they discussed at a big computer science conference this year.\n",
       "\n",
       "**Section 1:  What the Computers Can Do (Major Use Cases)**\n",
       "\n",
       "The computer scientists at the conference worked on many cool things!  Their work could help:\n",
       "\n",
       "* **Self-driving cars:**  Imagine cars that can drive themselves!  They need to understand how far away things are (depth), and some researchers are figuring out how to make those depth sensors even more reliable.\n",
       "* **3D modeling:**  Want to create your own video game or design a new toy?  These scientists are making it easier and faster to build realistic 3D models from just a few pictures.\n",
       "* **Robots:**  Robots can do amazing things, from working in factories to helping people at home. Some researchers are developing ways to make robots more easily learn new tasks by showing them videos.\n",
       "* **Image denoising:** Think of cleaning up blurry or noisy pictures – that’s image denoising.  This is important for clear pictures in medical scans, security cameras, and even satellite images.  \n",
       "* **Chatbots:** Ever talked to a chatbot?  Computer scientists are working on making them even better at understanding what you want and giving helpful answers, even if they are asked complex questions.\n",
       "* **Music Creation:** Can computers write songs? The answer is yes.  There were researchers making AI tools to make whole songs from just lyrics.\n",
       "* **Personalized recommendations:**  Think of suggestions from Netflix or Spotify.  Scientists are improving the computer's ability to give you recommendations tailored to you.\n",
       "* **Financial Markets:**  Analyzing financial data and predicting market trends to help make smart financial decisions.\n",
       "\n",
       "\n",
       "**Section 2:  What Problems the Computers Are Solving**\n",
       "\n",
       "These computer scientists were tackling some tough problems:\n",
       "\n",
       "* **Making self-driving cars safer:**  They’re working to prevent tricks that could make the self-driving car’s sensors go wrong (adversarial attacks).\n",
       "* **Creating more efficient 3D models:**  It takes a lot of time and computing power to make 3D models. They’re working on faster methods.\n",
       "* **Teaching robots more effectively:** It’s hard to teach robots new things. They're finding better ways for robots to learn from example videos.\n",
       "* **Removing noise from images:**  Blurry or noisy images make it hard to see what's important.  Scientists are developing ways to make these images clearer.\n",
       "* **Making chatbots more reliable:**  Chatbots can sometimes make things up or give the wrong answers.  Researchers are trying to make chatbots produce more accurate and truthful information.\n",
       "* **Protecting privacy:**  When we use computers to analyze data, we need to keep our private information safe.  Some researchers are developing new methods that keep this information private.\n",
       "* **Making AI more fair:**   Sometimes, AI makes mistakes and shows bias toward certain people or things. Researchers are working to prevent this.\n",
       "* **Efficiently using computing resources:** Large AI models are expensive to train and run. Scientists are working to make training more efficient.\n",
       "\n",
       "\n",
       "**Section 3: How the Problems Are Being Solved**\n",
       "\n",
       "The scientists use many clever techniques:\n",
       "\n",
       "* **Deep learning:**  This is like teaching computers to learn from examples, just like we do!\n",
       "* **Neural networks:**  These are computer models inspired by how our brains work. They have layers that process information, similar to how our brains do.\n",
       "* **Transformers:** A specific type of advanced neural network for processing sequential data like text and the sequence of pixels in images.\n",
       "* **Adversarial attacks:**  Tricking the AI into making mistakes to improve model robustness and detect weaknesses.\n",
       "* **Generative models:**  Teaching computers to create new images, text, or even sounds that look and sound realistic.  \n",
       "* **Reinforcement learning:**  Learning by trial and error, rewarding good behaviors and punishing bad ones.  This is used to train robots and AI decision systems.\n",
       "* **Bayesian methods:**  Considering uncertainty and probability to make more robust and reliable predictions.\n",
       "* **Optimal Transport:**  Finding the most efficient way to move things between different datasets, like transforming one style of image to another.\n",
       "* **Kernel Methods:** Efficiently analysing data using techniques from functional analysis and mathematical optimization.\n",
       "* **Graph Neural Networks:**  For analysing data with interconnected relationships (like customers, products in a supply chain, etc.)\n",
       "* **Other advanced math:**  These scientists are using very advanced mathematical tools to find the best solutions and prove that their solutions are correct!\n",
       "\n",
       "\n",
       "**Section 4:  The Future of Computer Science**\n",
       "\n",
       "There's still so much to discover!  Future research will focus on:\n",
       "\n",
       "* **More robust and reliable AI:**  Making AI systems less prone to errors and attacks.\n",
       "* **More efficient AI:**  Using less computing power and energy to train and run AI models.\n",
       "* **More explainable AI:** Making it easier to understand *why* an AI system makes a specific decision.\n",
       "* **Fairer AI:** Preventing AI from being biased toward specific groups of people or things.\n",
       "* **Continual learning:**  Making AI systems capable of learning new things throughout their lifetime without forgetting what they've already learned.\n",
       "* **More creative AI:**  Developing AI systems that can generate even more realistic and imaginative content.\n",
       "* **AI for understanding and influencing human preferences:**  Building AI models that produce outputs aligned with what people truly desire.\n",
       "* **Quantum computing:**  The potential to use the power of quantum mechanics to improve AI.  This could lead to breakthroughs in speed and capabilities.\n",
       "\n",
       "\n",
       "Computer science is a fantastic field.  There are lots of opportunities to make amazing things, solve big problems, and explore exciting ideas.  Who knows? Maybe some of you will be the next computer science superstars!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(o_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "075d49b5-333b-4d05-880c-700ac270d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_text = '''\n",
    "Hello everyone! Today, we're going on an exciting adventure into the world of computer science! Imagine computers that can understand pictures and videos, write stories, and even help design new products – that's what computer scientists do. I'm going to tell you about some amazing things they discussed at a big computer science conference this year.\n",
    "\n",
    "Section 1: What the Computers Can Do (Major Use Cases)\n",
    "\n",
    "The computer scientists at the conference worked on many cool things! Their work could help:\n",
    "\n",
    "Self-driving cars: Imagine cars that can drive themselves! They need to understand how far away things are (depth), and some researchers are figuring out how to make those depth sensors even more reliable.\n",
    "3D modeling: Want to create your own video game or design a new toy? These scientists are making it easier and faster to build realistic 3D models from just a few pictures.\n",
    "Robots: Robots can do amazing things, from working in factories to helping people at home. Some researchers are developing ways to make robots more easily learn new tasks by showing them videos.\n",
    "Image denoising: Think of cleaning up blurry or noisy pictures – that’s image denoising. This is important for clear pictures in medical scans, security cameras, and even satellite images.\n",
    "Chatbots: Ever talked to a chatbot? Computer scientists are working on making them even better at understanding what you want and giving helpful answers, even if they are asked complex questions.\n",
    "Music Creation: Can computers write songs? The answer is yes. There were researchers making AI tools to make whole songs from just lyrics.\n",
    "Personalized recommendations: Think of suggestions from Netflix or Spotify. Scientists are improving the computer's ability to give you recommendations tailored to you.\n",
    "Financial Markets: Analyzing financial data and predicting market trends to help make smart financial decisions.\n",
    "Section 2: What Problems the Computers Are Solving\n",
    "\n",
    "These computer scientists were tackling some tough problems:\n",
    "\n",
    "Making self-driving cars safer: They’re working to prevent tricks that could make the self-driving car’s sensors go wrong (adversarial attacks).\n",
    "Creating more efficient 3D models: It takes a lot of time and computing power to make 3D models. They’re working on faster methods.\n",
    "Teaching robots more effectively: It’s hard to teach robots new things. They're finding better ways for robots to learn from example videos.\n",
    "Removing noise from images: Blurry or noisy images make it hard to see what's important. Scientists are developing ways to make these images clearer.\n",
    "Making chatbots more reliable: Chatbots can sometimes make things up or give the wrong answers. Researchers are trying to make chatbots produce more accurate and truthful information.\n",
    "Protecting privacy: When we use computers to analyze data, we need to keep our private information safe. Some researchers are developing new methods that keep this information private.\n",
    "Making AI more fair: Sometimes, AI makes mistakes and shows bias toward certain people or things. Researchers are working to prevent this.\n",
    "Efficiently using computing resources: Large AI models are expensive to train and run. Scientists are working to make training more efficient.\n",
    "Section 3: How the Problems Are Being Solved\n",
    "\n",
    "The scientists use many clever techniques:\n",
    "\n",
    "Deep learning: This is like teaching computers to learn from examples, just like we do!\n",
    "Neural networks: These are computer models inspired by how our brains work. They have layers that process information, similar to how our brains do.\n",
    "Transformers: A specific type of advanced neural network for processing sequential data like text and the sequence of pixels in images.\n",
    "Adversarial attacks: Tricking the AI into making mistakes to improve model robustness and detect weaknesses.\n",
    "Generative models: Teaching computers to create new images, text, or even sounds that look and sound realistic.\n",
    "Reinforcement learning: Learning by trial and error, rewarding good behaviors and punishing bad ones. This is used to train robots and AI decision systems.\n",
    "Bayesian methods: Considering uncertainty and probability to make more robust and reliable predictions.\n",
    "Optimal Transport: Finding the most efficient way to move things between different datasets, like transforming one style of image to another.\n",
    "Kernel Methods: Efficiently analysing data using techniques from functional analysis and mathematical optimization.\n",
    "Graph Neural Networks: For analysing data with interconnected relationships (like customers, products in a supply chain, etc.)\n",
    "Other advanced math: These scientists are using very advanced mathematical tools to find the best solutions and prove that their solutions are correct!\n",
    "Section 4: The Future of Computer Science\n",
    "\n",
    "There's still so much to discover! Future research will focus on:\n",
    "\n",
    "More robust and reliable AI: Making AI systems less prone to errors and attacks.\n",
    "More efficient AI: Using less computing power and energy to train and run AI models.\n",
    "More explainable AI: Making it easier to understand why an AI system makes a specific decision.\n",
    "Fairer AI: Preventing AI from being biased toward specific groups of people or things.\n",
    "Continual learning: Making AI systems capable of learning new things throughout their lifetime without forgetting what they've already learned.\n",
    "More creative AI: Developing AI systems that can generate even more realistic and imaginative content.\n",
    "AI for understanding and influencing human preferences: Building AI models that produce outputs aligned with what people truly desire.\n",
    "Quantum computing: The potential to use the power of quantum mechanics to improve AI. This could lead to breakthroughs in speed and capabilities.\n",
    "Computer science is a fantastic field. There are lots of opportunities to make amazing things, solve big problems, and explore exciting ideas. Who knows? Maybe some of you will be the next computer science superstars!\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c408ad0-d8b8-4043-b4ad-ce8f7f650d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.paper_ontology import create_mp3\n",
    "\n",
    "create_mp3(overview_text, Path(PROJECT_DIR, 'overview.mp3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cdf650-b90f-444f-ae21-cfade53a624d",
   "metadata": {},
   "source": [
    "## Create Online File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d000809-2b4b-47a9-9d71-07b083180246",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_papers = [\n",
    "    'Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction'.lower(),\n",
    "    'Stochastic Taylor Derivative Estimator: Efficient amortization for arbitrary differential operators'.lower(),\n",
    "    'Not All Tokens Are What You Need for Pretraining'.lower(),\n",
    "    'Guiding a Diffusion Model with a Bad Version of Itself'.lower(),\n",
    "    'The PRISM Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models'.lower()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acdf654c-8a8f-4b6f-add2-f4ab7cc1325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_paper_data = []\n",
    "required_fields = ['title', 'summary', 'category']\n",
    "\n",
    "for p in all_papers:\n",
    "    new_p = {key: p[key] for key in required_fields if key in p}\n",
    "    new_p['category'] = p['info']['category']\n",
    "    if p['title'].lower() in best_papers:\n",
    "        new_p['best_paper'] = 1\n",
    "    else:\n",
    "        new_p['best_paper'] = 0\n",
    "    streamlit_paper_data.append(new_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8f0de043-ebe9-4ede-8be3-dbaaafe4ce09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Computer Vision'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamlit_paper_data[0]['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df5d0568-06e5-46be-aa36-be9f9f3bbc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3990"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(streamlit_paper_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e0f28cd-1b83-4cc8-8a01-bd7f5a86b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_data = (streamlit_paper_data, o_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf8c8e44-6030-49f1-a91a-b92ad881d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(PROJECT_DIR, 'streamlit_nips_data.pkl'), 'wb') as f:\n",
    "    pickle.dump(streamlit_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9ba32-9690-43d8-97e6-84bb5ca211a5",
   "metadata": {},
   "source": [
    "## Index to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c85d18-6c02-4800-87a2-8838eee0c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from importlib import reload # python 2.7 does not require this\n",
    "#import utils.paper_QA\n",
    "#reload(utils.paper_QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "66210eb6-d8fe-416d-8b72-5a200947d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.paper_QA import paper2doc\n",
    "\n",
    "docs = paper2doc(all_papers, 'nips2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74b0bed1-2f6c-415b-98b0-a10656039411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30793"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a79559d-79d7-4853-9e09-4498c4c87700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.paper_QA import EmbeddingDB\n",
    "\n",
    "NEO4J_URI='neo4j+s://e0a3a179.databases.neo4j.io'\n",
    "NEO4J_USERNAME='neo4j'\n",
    "NEO4J_PASSWORD='<>'\n",
    "\n",
    "db = EmbeddingDB(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD, [docs[101]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba6e9c1f-45d1-46f4-bb71-c9475d6dd4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.insert(docs[3:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1dc5e5c0-c3bd-4390-970d-dfd2545f5aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 26700it [4:04:48,  2.80it/s]                                                                                   "
     ]
    }
   ],
   "source": [
    "#for i in tqdm(range(102, len(docs), 100)):\n",
    "#    db.insert(docs[i:min(i+100, len(docs))])\n",
    "#    time.sleep(30)\n",
    "\n",
    "all_ps = docs[4102:]\n",
    "pbar = tqdm(desc=\"Processing\", total=len(all_ps))\n",
    "\n",
    "i = 0\n",
    "while i < len(all_ps):\n",
    "    try:\n",
    "        p = all_ps[i]\n",
    "        db.insert(docs[i:min(i+100, len(all_ps))])\n",
    "        i += 100\n",
    "        pbar.update(100)\n",
    "        time.sleep(30)\n",
    "    except:\n",
    "        print('deadline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7c241-8aab-42be-801a-adee9f7ee8b8",
   "metadata": {},
   "source": [
    "## Query Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bc8f3f93-0343-47ee-bca1-00caa469cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "    driver.verify_connectivity()\n",
    "    print(\"Connection established.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53d3edbb-b793-427d-a863-b901392396fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jVector\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "index_name = \"vector\"  # default index name\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n",
    "store = Neo4jVector.from_existing_index(\n",
    "    embeddings,\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "44335d76-111a-403a-a9a5-0969d5a9bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'image classification'\n",
    "test = store.similarity_search_with_score(query, k=5, filter={'tag':'icml2024'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a39dbd4f-3c80-4b82-b0cc-895ffd1f6bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'section_title': 'Impact Statement', 'title': 'Tell, Don’t Show!: Language Guidance Eases Transfer Across Domains in Images and Videos', 'tag': 'icml2024'}, page_content='Our paper presents an approach that can improve accuracy\\non domains facing label scarcity. Advancing this research\\narea would enhance wider adoption of current AI technolo-\\ngies, and unlocks new capabilities in democratizing the\\nprogress in AI. Given that our proposed methodology only\\noperates in the standard realm of image classification and\\nour showcased results only use already publicly available\\ndatasets, we do not foresee any negative societal conse-\\nquences specifically arising due to our method.\\n'),\n",
       "  0.8202242851257324),\n",
       " (Document(metadata={'section_title': '5. Limitation', 'title': 'Generalization with Class Taxonomies', 'tag': 'icml2024'}, page_content='While we benchmarked and used LCA based on class\\nhierarchy to measure model generalization, the findings\\nfrom this work indicate that it is not an effective indica-\\ntor for datasets visually similar to in-distribution data (like\\nImageNet2, more discussion in Appendix  B ). For these\\ndatasets, in-distribution Top1 remains a strong indicator,\\nwhich potentially limits the utility of LCA. Also, it’s ex-\\npected that LCA will show a weaker discrimination between\\nmodels on datasets with small number of classes (like Ci-\\nfar ( Krizhevsky et al. )).\\n'),\n",
       "  0.816133975982666),\n",
       " (Document(metadata={'section_title': '5. Experimental Evaluation', 'title': 'Fine-grained Classes and How to Find Them', 'tag': 'icml2024'}, page_content='5.1. Quantitative Results\\nFine-grained class discovery.  We compare FALCON to al-\\nternative baselines on eight image classification datasets and\\na single-cell dataset. The results in Table  2  show that FAL-\\nCON outperforms baselines by a large margin on both image\\nand single-cell data. For example, on the BREEDS bench-\\nmark of four datasets (Living17, Nonliving26, Entity30,\\nEntity13) FALCON achieves an average improvement of\\n9%  in terms of accuracy and  16%  in terms of ARI over\\nthe best baselines. On the tieredImageNet dataset with  608\\nfine-grained classes grouped into  34  coarse classes, FAL-\\nCON outperforms the best baseline ANCOR by  12%  and\\n22%  in terms of accuracy and ARI, respectively. Moreover,\\nimprovements of FALCON can be observed on both bal-\\nanced (BREEDS benchmark and CIFAR100), as well as\\nunbalanced datasets (CIFAR68, CIFAR-SI, tieredImageNet\\nand single-cell PBMC).\\nEvaluation of learned class relationships.  FALCON in-\\nfers the mapping between fine-grained and coarse-grained\\nclasses. We next evaluate how well the inferred coarse-fine\\nclass relationships agree with the ground truth relationships\\nusing the graph edit distance (GED). The graph edit distance\\nof zero indicates that two graphs are the same and the ground\\ntruth relationships are perfectly inferred. We compare FAL-\\nCON with SCGM which learns class relations implicitly\\nthrough a data generation process. The results shown in\\nTable  3  demonstrate that FALCON can perfectly match the\\nground truth relations for all balanced datasets which is not\\nthe case for the SCGM. For the imbalanced datasets, not\\nall class relationships are correctly recovered but FALCON\\nstill substantially outperforms SCGM on all datasets. The\\ndiscrepancy between the learned and the ground-truth rela-\\ntions comes from the fact that ( 14 ) finds the optimal solution\\ngiven a classifier  f θ . Thus, the obtained solution may differ\\nfrom the true optimal solution. This discrepancy could be\\nmitigated by employing a stronger classifier ( Radford et al. ,\\n2021 ).\\nTraining on multiple datasets.  FALCON can learn from\\nmultiple datasets labeled with different coarse-level classes\\n(Section  3.4 ). We evaluate the effectiveness of FALCON\\non the CIFAR100 dataset. The CIFAR100 dataset has a\\n6\\ndefault grouping of  100  fine classes into  20  coarse classes\\nwhich we denote with T1. We construct a meaningful alter-\\nnative grouping of fine classes into coarse classes, which we\\ndenote as T2. For example, the default grouping T1 arbitrar-\\nily divides  10  fine-grained vehicle classes into two coarse\\nclasses named  Vehicles1  and  Vehicles2 . On the contrary, our\\nalternative taxonomy groups fine-grained vehicle classes\\ninto  Personal Vehicles  and  Transit Vehicles  (see Appendix\\nI  for the full list of coarse classes in each taxonomy). We\\nsplit the training set into two halves and label the first half\\naccording to T1 and the second half according to T2. Thus,\\nthe resulting splits, denoted with  D 1  and  D 2 , correspond to\\ntwo datasets with the same underlying set of fine-grained\\nclasses and different coarse classes. We keep the CIFAR100\\ntest set unmodified to track the generalization performance\\nfor different training configurations.\\nTable  4  shows the results of using FALCON to simultane-\\nously learn from two coarsely labeled datasets with different\\nlabeling policies. The top two rows show fine-grained accu-\\nracy and ARI after training FALCON on  D 1  or  D 2 . Com-\\npared to FALCON trained on a single dataset, we observe\\n14%  relative improvement according to ARI and  10%  rela-\\ntive improvement according to clustering accuracy. These\\nresults indicate that FALCON can effectively utilize differ-\\nent labeling policies to improve performance.\\nTo evaluate the benefits of training from multiple datasets\\nusing baseline methods, we train SCAN-C on the same\\ndatasets. While SCAN-C can simultaneously learn from\\nmultiple datasets, the gains from different labelings are\\nmarginal compared to FALCON (2% improvement in terms\\nof ARI).\\nAggregating multiple training datasets implicitly increases\\nthe number of training samples and thus improves the gen-\\neralization. Hence, we analyze the influence of different la-\\nbeling policies in isolation by repeating the experiment with\\nan equal number of samples in each training dataset from\\nTable  4 . The results, summarized in Appendix  J , confirm\\nthat FALCON can effectively utilize the different labeling\\npolicies. For example, FALCON trained on taxonomies\\nT1&T2 improves 7% in terms of accuracy over the FAL-\\nCON trained only on T2. Contrary, SCAN-C trained on\\nT1&T2 improves only 1% over the SCAN-C trained only\\non T2. Altogether, these results indicate that FALCON\\ncan effectively learn from multiple datasets labeled with\\ndifferent labeling policies.\\n5.2. Qualitative Results\\nWe next visually inspect the quality of the embedding space\\nlearnt by FALCON. Figure  2  shows two-dimensional t-SNE\\nplot ( Hinton & Roweis ,  2002 ) of the embedding space learnt\\nby FALCON on the Living17 dataset. The results show that\\nsamples assigned to the same coarse-grained classes are\\nseparated into multiple fine-grained classes.\\nTo validate that these fine classes are correct and represent\\ndifferent subspecies of animals, we look into representative\\nexamples from every fine-grained class and confirm that the\\nexamples indeed reflect different subcategories. For exam-\\nple, the four fine classes of coarse class  Spider  correspond\\nto subspecies of spiders including  Barn spider ,  Tarantula ,\\nGarden spider , and  Black and gold spider . Similarly, the\\ninferred fine-grained classes of  Grouse  correspond to  Black\\ngrouse ,  Prairie grouse ,  Ruffed grouse  and  Ptarmigan . This\\n7\\nindicates that the embedding space learnt by FALCON in-\\ndeed reflects fine-grained representations.\\nWe next visualize the three most confident predictions for\\ndifferent fine-grained classes. Figure  3  shows the three most\\nconfident samples for every fine-grained class associated\\nwith coarse classes  Salamander  and  Bear  from the Living17\\ndataset. We validate the recovered fine-grained classes and\\nconfirm that they indeed correspond to different salaman-\\nder subspecies ( Axolotl ,  Common newt ,  Eft , and  Spotted\\nsalamander ) and bear subspecies ( Sloth bear ,  Black bear ,\\nPolar bear , and  Brown bear ). This indicates that FALCON\\nproduces meaningful fine-grained classes even when differ-\\nences between these subclasses are very subtle. We show\\nmore examples in the Appendix  K .\\nFALCON can also discover subclasses within existing fine-\\ngrained classes. To showcase this, we set 68 fine classes\\nof the Living17 dataset as coarse classes and increased the\\nexpected number of fine-grained classes. Figure  4  shows\\nthe two subclasses discovered within classes  Eft  and  Ptarmi-\\ngan . The newly discovered subclasses differ by skin and\\nfeather color. Unfortunately, this evaluation can only be\\nqualitatively verified since the appropriate ground-truth is\\nunavailable. More visual examples can be found in Ap-\\npendix  L .\\n5.3. Ablation Studies\\nComponents of the objective.  We next conduct ablation\\nstudies on the classifier’s objective function ( 10 ) which con-\\nsists of coarse supervision  L coarse , fine-grained consistency\\nand confidence  L fine , and entropy regularization  L reg . To in-\\nvestigate the importance of each part, we modify FALCON\\nby removing each loss component and then measure fine-\\ngrained clustering accuracy and ARI. We show the results\\non the CIFAR100 dataset in Table  5 . Removing  L fine  results\\nin divergent fine-grained predictions for similar samples.\\nThus, the samples are arbitrarily grouped into subclasses\\nand we observe poor fine-grained performance. Removing\\nL reg  results in a skewed distribution of samples across fine-\\ngrained classes and poor fine-grained performance. Remov-\\ning  L coarse  eliminates coarse-level supervision and prevents\\njoint learning of class relationships. Thus we also have to\\nremove  L conf  since it relies on class relations. Again, we\\nobserve a notable performance drop. This ablation con-\\nfirms that all three losses contribute to strong fine-grained\\nperformance.\\nEstimated number of fine-grained classes.  FALCON\\ntakes the expected number of fine-grained classes as a hy-\\nperparameter. However, in practice, we often do not know\\nthe number of classes in advance. In such a case, we can\\nfirst estimate the number of novel classes. We estimate the\\nnumber of classes as proposed in ( Wang et al. ,  2018 ) and\\nobtain  89  for the CIFAR100 dataset and  76  for the CIFAR68\\ndataset. We then train FALCON with the estimated number\\nof fine-grained classes  K F  . The results are shown in Table\\n6 .\\n8\\nRemarkably, on the CIFAR100 dataset, FALCON with the\\nestimated number of classes outperforms all other baselines\\ntrained with the ground truth number of fine classes. On the\\nCIFAR68 dataset, FALCON outperforms all baselines ex-\\ncept GEORGE which attains slightly better accuracy. FAL-\\nCON’s sensitivity on different values of  K F  can be found\\nin Appendix  M .\\nAdditional ablation studies.  We validate the fine-grained\\nperformance for different hyperparameter values on CI-\\nFAR100. We validate  λ M  from ( 14 ), temperature  T  from\\n( 7 ), and three loss modulation hyperparameters  λ 1 , λ 2  and\\nλ 3  from ( 10 ). The results are summarized in Appendix  N .\\nFALCON is robust to different values of hyperparameters.\\nIn addition, we evaluate the performance of FALCON with\\nground truth class relations in Appendix  O . The results in-\\ndicate that estimating class relations does not significantly\\naffect the fine-grained classification performance. Thus,\\nknowing class relations beforehand is not mandatory for\\ngood fine-grained performance.\\n'),\n",
       "  0.8062753677368164),\n",
       " (Document(metadata={'section_title': 'Abstract', 'title': 'Fine-grained Classes and How to Find Them', 'tag': 'icml2024'}, page_content='In many practical applications, coarse-grained\\nlabels are readily available compared to fine-\\ngrained labels that reflect subtle differences be-\\ntween classes. However, existing methods cannot\\nleverage coarse labels to infer fine-grained labels\\nin an unsupervised manner. To bridge this gap,\\nwe propose FALCON, a method that discovers\\nfine-grained classes from coarsely labeled data\\nwithout any supervision at the fine-grained level.\\nFALCON simultaneously infers unknown fine-\\ngrained classes and underlying relationships be-\\ntween coarse and fine-grained classes. Moreover,\\nFALCON is a modular method that can effectively\\nlearn from multiple datasets labeled with differ-\\nent strategies. We evaluate FALCON on eight\\nimage classification tasks and a single-cell classi-\\nfication task. FALCON outperforms baselines by\\na large margin, achieving  22%  improvement over\\nthe best baseline on the tieredImageNet dataset\\nwith over  600  fine-grained classes.\\n'),\n",
       "  0.8055568933486938),\n",
       " (Document(metadata={'section_title': '6. Conclusions', 'title': 'Generalization with Class Taxonomies', 'tag': 'icml2024'}, page_content='This work revitalizes the use of LCA distance, leveraging\\nclass taxonomies such as WordNet, to indicate model OOD\\nperformance. We assess the severity of model mispredic-\\ntions in a manner agnostic to model modality or architecture,\\nestablishing a comprehensive metric for evaluating model\\ngeneralization. Our findings, across multiple ImageNet-\\nOOD datasets, highlight the superiority of LCA distance in\\nreflecting the generalization capabilities of models trained\\nwith either class labels (VMs) or captions (VLMs), surpass-\\ning the traditional reliance on in-distribution Top-1 accu-\\nracy ( Miller et al. ,  2021 ). Additionally, we demonstrate that\\naligning model predictions with class taxonomies, through\\nsoft labels or prompt engineering, can enhance model gen-\\neralization. To extend the application of LCA distance mea-\\nsurement to any dataset, we introduce a method for creating\\nlatent hierarchies using K-means clustering, showcasing the\\nresilience of LCA distance regardless of the applied tax-\\nonomy or hierarchy. This work offers new insights into\\nmodel generalization by leveraging existing resources and\\nencourages further research in this direction.\\nFuture research could focus on providing theoretical justi-\\nfication for the LCA-on-the-Line framework. For instance,\\nexploring causal discovery ( Brouillard et al. ,  2020 ) meth-\\nods on the ImageNet dataset to construct a causal graph\\nbetween classes and underlying variables may offer a more\\naccurate reflection of causal relationships between classes.\\nAdditionally, conducting larger-scale empirical studies to\\nfurther validate this benchmark would be beneficial.\\n'),\n",
       "  0.8047447204589844)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79802871-e3a8-477a-a71d-48a5a36dc309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
